---
title: "dada2_RCode"
output: html_document
---

# Call library
library(dada2)

# Setting fastq file path
path <- 'D:/Pesquisas_sequenciamento/Pennstate/Kit_comparison/qiime2-2020.8/results paper/Dada2/Kit1/' 
list.files(path)

## dada2 pipeline

#  Extract sample names

fnFs1 <- sort(list.files(path,pattern = "_R1.fastq", full.names = TRUE))
fnFs1
fnRs1 <- sort(list.files(path, pattern = "_R2.fastq", full.names = TRUE))
fnRs1

sample.names1 <- sapply(strsplit(basename(fnFs1), " "), '[', 1)
sample.names1

# Quality profiles
plotQualityProfile(fnFs1[1:12])
plotQualityProfile(fnRs1[1:12])

# Filter and trim
filtFs1 <- file.path(path, 'filtered1', paste0(sample.names1,"_F_filt.fastq.gz"))
filtRs1 <- file.path(path, 'filtered1', paste0(sample.names1,"_R_filt.fastq.gz"))

names(filtFs1) <- sample.names1
names(filtRs1) <- sample.names1

names(filtFs1)
names(filtRs1)

out1 <- filterAndTrim(fnFs1, filtFs1, fnRs1, filtRs1, truncLen = c(275, 280),trimLeft = c(20,20),maxN=0, maxEE=c(2,2), truncQ=2, rm.phix=TRUE,compress=TRUE, multithread=FALSE)

(out1,n = 12)

# Quality check 2

plotQualityProfile(filtFs1[1:12])
plotQualityProfile(filtRs1[1:12])

# Error Rates

errF1 <- learnErrors(filtFs1, multithread = FALSE)
errR1 <- learnErrors(filtRs1, multithread = FALSE)

plotErrors(errF1, nominalQ=TRUE)
plotErrors(errR1, nominalQ=TRUE)

#  Sample Inference

dadaFs1 <- dada(filtFs1, err=errF1, multithread=FALSE)
dadaRs1 <- dada(filtRs1, err=errR1, multithread=FALSE)

#  Inspecting the returned dada-class object:
dadaFs1[[12]]
dadaRs1[[12]]

#  Merge paired-reads
mergers1 <- mergePairs(dadaFs1, filtFs1, dadaRs1, filtRs1, verbose = TRUE)
mergers1

# Inspect the merger data.frame from the first sample
head(mergers1[[1]])

#  Construct sequence table
seqtab1 <- makeSequenceTable(mergers1)
dim(seqtab1)

#  Inspect distribution of sequence lengths
length1 <- table(nchar(getSequences(seqtab1)))
length1

seqtab1.1 <- seqtab1[,nchar(colnames(seqtab1)) %in% 262:264]
seqtab1.1

dim(seqtab1.1)
table(nchar(getSequences(seqtab1.1)))

#  Removing chimeras
seqtab1.1.nochim <- removeBimeraDenovo(seqtab1.1, method = "consensus", multithread=FALSE, verbose = TRUE)
dim(seqtab1.1.nochim)
sum(seqtab1.1.nochim/sum(seqtab1.1))

#  Track reads through the pipeline
getN <- function(x) sum(getUniques(x))
track <- cbind(out1, sapply(dadaFs1, getN), sapply(dadaRs1, getN), sapply(mergers1, getN), rowSums(seqtab1.1.nochim))

# If processing a single sample, remove the sapply calls: e.g. replace sapply(dadaFs, getN) with getN(dadaFs)
colnames(track) <- c("input", "filtered", "denoisedF", "denoisedR", "merged", 'nochim')
rownames(track) <- sample.names1
track

## Do the previous pipeline for each dataset 


# Save each seqtab as .rds
saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab1.rds") # kit 1 analysis

saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab2.rds") # kit 2 analysis

saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab3.rds") # kit 3 analysis

saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab4.rds") # kit 4 analysis

# Save each seqtab.nochim as .rds
saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab1_nochim.rds") # kit 1 analysis

saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab2_nochim.rds") # kit 2 analysis

saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab3_nochim.rds") # kit 3 analysis

saveRDS(seqtab1, "C:/Users/gecre/OneDrive/Dada2/Kit1/seqtab4_nochim.rds") # kit 4 analysis

#  Merge multiple runs (each dataset)
nc1 <- readRDS('C:/Users/gecre/OneDrive/Dada2/seqtab1_nochim.rds')

nc2 <- readRDS('C:/Users/gecre/OneDrive/Dada2/seqtab2_nochim.rds')

nc3 <- readRDS('C:/Users/gecre/OneDrive/Dada2/seqtab3_nochim.rds')

nc4 <- readRDS('C:/Users/gecre/OneDrive/Dada2/seqtab4_nochim.rds')

nc_all <- mergeSequenceTables(nc1, nc2, nc3, nc4)

# Assign taxonomy from merged table
tax_all <- assignTaxonomy(nc_all, "C:/Users/gecre/OneDrive/Dada2/silva_nr99_v138_train_set.fa.gz", multithread=TRUE)

# Save each tax_all as .rds
saveRDS(tax_all, "C:/Users/gecre/OneDrive/Dada2/tax_all.rds")

# Inspecting taxa
taxa.print <- tax_all
row.names(taxa.print) <- NULL
taxa.print

# Evaluate accuracy
unqs.mock1 <- nc_all['Kit1PosCtrlPC_R1.fastq.gz',]
unqs.mock1 <- sort(unqs.mock1[unqs.mock1>0], decreasing = T)
cat("DADA2 inferred", length(unqs.mock1), "sample sequences present in the Mock community.\n")

unqs.mock2 <- nc_all['Kit2PosCtrlPC_R1.fastq.gz',]
unqs.mock2 <- sort(unqs.mock2[unqs.mock2>0], decreasing = T)
cat("DADA2 inferred", length(unqs.mock2), "sample sequences present in the Mock community.\n")

unqs.mock3 <-nc_all['Kit3PosCtrlPC_R1.fastq.gz',]
unqs.mock3 <- sort(unqs.mock3[unqs.mock3>0], decreasing = T)
cat("DADA2 inferred", length(unqs.mock3), "sample sequences present in the Mock community.\n")

unqs.mock4 <- nc_all['Kit4PosCtrlPC_R1.fastq.gz',]
unqs.mock4 <- sort(unqs.mock4[unqs.mock4>0], decreasing = T)
cat("DADA2 inferred", length(unqs.mock4), "sample sequences present in the Mock community.\n")
